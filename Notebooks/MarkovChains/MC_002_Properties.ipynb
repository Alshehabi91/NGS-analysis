{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkekGi6um5xh"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/thomasmanke/ABS/blob/main/Notebooks/MarkovChains/MC_002_Properties.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBcpbeidC5tf"
      },
      "source": [
        "# Analysing Markov chain properties"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvBkP1ymcFTV"
      },
      "source": [
        "## Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36CJgM09bhgx"
      },
      "source": [
        "Import Required Modules and Define Convenience Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9T6rVFQ5bMNZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.linalg import matrix_power\n",
        "\n",
        "\n",
        "\n",
        "def generate_sequence(P, s=0, T=100):\n",
        "\n",
        "  assert P.shape[0]==P.shape[1],         \"generate_sequence: P should be a squared matrix\"\n",
        "  assert np.allclose( P.sum(axis=1), 1), \"generate_sequence: P should be a stochastic matrix\"\n",
        "\n",
        "  ns = P.shape[0] # number of states\n",
        "  L = [s]         # initial state\n",
        "\n",
        "  # loop for T time steps\n",
        "  for t in range(T):\n",
        "    s = np.random.choice( ns, p = P[s, :] )\n",
        "    L.append(s)\n",
        "  return L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loRGD_8Gaksa"
      },
      "source": [
        "Let's make sure we start from the same model (transition probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdIUgzObalUp"
      },
      "outputs": [],
      "source": [
        "P = np.array(\n",
        "    [[0.8, 0.2], \n",
        "     [0.1, 0.9]]\n",
        ")\n",
        "X=generate_sequence(P)\n",
        "print(*X, sep='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyedJHsprYJy"
      },
      "source": [
        "## Probability of a Sequence\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIfGKWKZe4di"
      },
      "source": [
        "The probability of an observed state sequence $X=(X_1, X_2, \\ldots X_T)=X_{1:T}$ is an important quantity: \n",
        "\n",
        "$$\n",
        "Pr(X|P) = Pr(X_1) Pr(X_2|X_1) Pr(X_3|X_2) \\cdots Pr(X_T|X_{T-1})\n",
        "$$\n",
        "\n",
        "It may be used to classify a given observation $X$ as more or less likely to emerge from different models\n",
        "\n",
        "$$\n",
        "Pr(X|P_1) < Pr(X|P_2) \n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBwl-jB0hC54"
      },
      "source": [
        "**Group Task (20 min)**: Strange coins\n",
        "\n",
        "Your favorite casino seems to use very strange coins and you try 2 different Markov models to model the occurence of heads (0) and tails (1). The transition probabilities read \n",
        "\n",
        "$$\n",
        "P_1 = \\begin{bmatrix} \n",
        "0.2   &  0.8 \\\\ \n",
        "0.8   &  0.2 \n",
        "\\end{bmatrix} \n",
        "$$\n",
        "\n",
        "\\\n",
        "\n",
        "$$\n",
        "P_2 = \\begin{bmatrix} \n",
        "0.8   &  0.2 \\\\ \n",
        "0.8   &  0.2 \n",
        "\\end{bmatrix} \n",
        "$$\n",
        "\n",
        "You also assume that the initial probability for observing heads (0) or tails (1) is 50% in both cases.\n",
        "\n",
        "1. Give a verbal account of the model and contrast this with a fair dice.\n",
        "2. Complete the code block below to calculate the probability of the sequence $X=0010000011$ under your model. \n",
        "3. Can you calculate the probability for a fair dice analytically (with a simple formula)?\n",
        "4. Exchange the results with the other group and decide which model is more likely.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g51qgZ8xHr7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d78c861-ebec-4dc4-af09-21c6375853af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0010485760000000005\n",
            "0.0009765625\n"
          ]
        }
      ],
      "source": [
        "#%%script echo Edit before executing\n",
        "X = [0,0,1,0,0,0,0,0,1,1]\n",
        "P2 = np.array([[0.8,0.2], [0.8,0.2]])\n",
        "pfair = np.array([[0.5,0.5],[0.5,0.5]])\n",
        "\n",
        "def probcal(Z,Seq):\n",
        "  prob = 0.5                   # initial probability: P(x_1=0)\n",
        "# loop over all edges in chain \n",
        "  for t in range(len(Seq)-1):\n",
        "    x1= X[t]                  # current state\n",
        "    x2= X[t+1]                  # next state\n",
        "    prob = prob*Z[x1,x2]\n",
        "  return prob          # probability update\n",
        "\n",
        "    # you might want to print for debugging\n",
        "    #print('t={}, x1={}, x2={} P[s1,s2]={}'.format(t,x1,x2, P[x1,x2]) )\n",
        "\n",
        "print(probcal(P2,X))\n",
        "print(probcal(pfair,X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGXxgpsQtf8h"
      },
      "source": [
        "**Follow up:** Duplicate (repeat) the sequence $X$ to obtain a new $X$ with twice the length?  What can you say about the probability?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDOiqK2ieDXs"
      },
      "source": [
        "**Messages**\n",
        "- Markov Models are probabilistic models: given the transition matrix $P$ we can calculate many interesting probabilities\n",
        "- More specifically: the probability of a given sequences. Decreases with sequence length - better use logs for long sequences!\n",
        "- Two approaches: Mathematical Treatment of stochastic matrices vs Numerical Simulations (algorithmic efficiency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxXf-xyvN89Z"
      },
      "source": [
        "## counting occurrences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bjew5NxYOCrW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e6c01dc7-318d-416a-884c-fb1c15c7c1de"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# define new transition matrix\n",
        "P = np.array( [[0.8, 0.2], [0.1, 0.9]] )\n",
        "np.random.seed(42)\n",
        "X = generate_sequence(P, s=0, T=1)\n",
        "\n",
        "states, counts = np.unique(X, return_counts=True)\n",
        "B = plt.bar(states.astype(str), counts, align='center', width=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCmuXb-EZZN1"
      },
      "source": [
        "**Task (5 min):** \n",
        "\n",
        "Repeat the above plot for different initial states s and different length of sequences. \n",
        "\n",
        "What do you observe?\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg9FQsbgYAXx"
      },
      "source": [
        "## Calculating higher order probabilities\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8PLIggIpQey"
      },
      "source": [
        "A Markov Model is defined by all 1-step transition probabilities: $P_{ij}$ (for $i \\to j$). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikuledjoRgUC"
      },
      "source": [
        "What is the probability for transitions $i \\to j$ in 2 steps, 3 steps, ...t-steps?\n",
        "\n",
        "$$P_{ij}(t) = P(X_t = j | X_0 = i)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL1uJdIYiBW6"
      },
      "source": [
        "**Group task (15 min):**  Consider a specific case for the given $P$ above.\n",
        "Starting at $t=0$ in *state i=0*, what are the probabilities at time $t$\n",
        "\n",
        "Group 1:  to be in *state j=0*?\n",
        "\n",
        "Group 2:  to be in *state j=1*?\n",
        "\n",
        "In other words:  Group 1 $\\to$ Calculate $P_{00}(t)$. Group 2 $\\to$ Calculate $P_{01}(t)$.\n",
        "\n",
        "a) at time t=1 ?\n",
        "    \n",
        "b) at time t=2 ?\n",
        "\n",
        "**Hint:** Consider all paths that go from $i \\to j$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-88xYRiOiBW6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "556ab3cf-3a28-419b-8523-625d6bd38e58"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-54f9972a61d3>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print(P[0,1])\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#%%script echo Edit before executing\n",
        "\n",
        "P = np.array(\n",
        "    [[0.8, 0.2], \n",
        "     [0.1, 0.9]]\n",
        "\n",
        "print(P[0,1])\n",
        "print('P01(t=1):'+str(P[0,1]))\n",
        "print('P01(t=2  1st:): '+str(P[0,0]*P[0,1]))\n",
        "print('P01(t=2  2nd:): '+str(P[0,1]*P[1,1]))\n",
        "print('P00(t=1): '+str(P[0,0])) \n",
        "print('P00(t=2) 1st : '+str(P[0,0]*P[0,0])) \n",
        "print('P00(t=2) snd : '+str(P[0,1]*P[1,0]))\n",
        "print(p[0,1]*p[1,0]+*[p[0,0]])\n",
        "print([[0,0]*p[0,1]+*p[0,1]*p[1,1]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju87QJrnmYwW"
      },
      "source": [
        "For larger $t$, these calculations can fast become cumbersome ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHIuANrqDKaH"
      },
      "source": [
        "### Generalization and Simplification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh8MM62vEvbZ"
      },
      "source": [
        "Required Tools:\n",
        "1. Matrix Multiplication: $C_{ij} = \\sum_k A_{ik}B_{kj}$\n",
        "2. Marginalization: $P(A) = \\sum_B P(A|B) P(B)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzd27UXwR9C2"
      },
      "source": [
        "1. **Initialization:**  $P_{ij}(t=0) = \\delta_{ij}$\n",
        "2. **1-step probabilties:**  $P_{ij}(t=1) = P_{ij}$  (Definition of Markov Chain)\n",
        "3. **Recursion:** (marginalization over all states at time $t$)\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        " Pr(X_{t+1}=j|X_0=i) &= \\sum_k Pr(X_{t+1}=j | X_t=k, X_0=i) \\cdot Pr(X_t=k|X_0=i) \\\\ \n",
        " &= \\sum_k Pr(X_{t+1}=j | X_t=k) \\cdot Pr(X_t=k|X_0=i) \\\\ \n",
        " P_{ij}(t+1) &= \\sum_k P_{kj} \\cdot P_{ik}(t) = (P^t)_{ij}\n",
        " \\end{align}\n",
        " $$\n",
        "\n",
        "\n",
        "$\\sum_k$ is the sum over all connections from state $k$ to $j$, and $p_{ik}(t)$ is the previous result over all possible pathways from $i$ to $k$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGqgiBiAYrkH"
      },
      "source": [
        "The above is for the t-step transition matrix. \n",
        "For the probability distribution over states we have:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        " Pr(X_{t}=j) &= \\sum_k Pr(X_t=j | X_o=k) \\cdot Pr(X_0=k) \\\\ \n",
        "             &= \\sum_k P_{kj}(t) \\cdot Pr(X_0=k)\n",
        " \\end{align}\n",
        " $$\n",
        "\n",
        "**Simplification**: (in vector notation)\n",
        "\n",
        "$$\\pi(t) = \\pi(0) \\cdot P^t$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnkleWlHFDCe"
      },
      "source": [
        "**Task (5min)**: Matrix Power\n",
        "\n",
        "Explore the function matrix_power() and apply this function to $P$ with an increasing value of $t$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "05D2BvLVFJus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30dac3cc-d429-4db4-89e0-d5b0ef633206"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8, 0.2],\n",
              "       [0.1, 0.9]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#%%script echo Edit before executing\n",
        "from numpy.linalg import matrix_power\n",
        "p = np.array([[0.8, 0.2], [0.1, 0.9]])\n",
        "t=1\n",
        "matrix_power( p, t )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHCFLR49iBW8"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "**Task (10 min):** Deja-vu\n",
        "    \n",
        "Starting in state 0 at t=0, calculate the probabilities to be in state 1\n",
        "    \n",
        "a) at time t=1 ?\n",
        "    \n",
        "b) at time t=2 ?\n",
        "    \n",
        "c) at time t=20 ?\n",
        "\n",
        "Solve it using matrix multiplication: https://numpy.org/doc/stable/reference/generated/numpy.linalg.matrix_power.html\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txhkVX4OiBW9"
      },
      "outputs": [],
      "source": [
        "%%script echo Edit before executing\n",
        "from numpy.linalg import matrix_power\n",
        "pi_0 =        # initial probability\n",
        "pi_t =        # dot product of initial probability with P^k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALB14r_AiBW9"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "**Task (5 min):** \n",
        "\n",
        "Repeat the above question with state 1 at t=0.\n",
        "\n",
        "    \n",
        "a) at time t=1 ?\n",
        "    \n",
        "b) at time t=2 ?\n",
        "    \n",
        "c) at time t=20 ?\n",
        "    \n",
        "\n",
        "**Extra:** Repeat the above with an uncertain state $\\pi=[0.5, 0.5]$\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF7ffFIwONhz"
      },
      "source": [
        "**Question:** What is different?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPG6zB0VOM6u"
      },
      "source": [
        "**Lessons**: \n",
        "\n",
        "1. Importance of recursions\n",
        "1. Matrix multiplication is powerful tool (and easy with Python/Numpy)! \n",
        "2. Matrix powers of $(P^t)_{ij}$ give the t-step transition probabilities from $i$ to $j$ \n",
        "3. $\\pi(t) = \\pi(0) \\cdot P^t$ gives the state probability distribution at time $t$\n",
        "4. Important role of linear algebra, efficient algorithms and tools\n",
        "5. Convergence and Independence of Initial State "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrSiWwiZyoaI"
      },
      "source": [
        "## Long-time Properties\n",
        "\n",
        "Given this image of a Markov Chain, can you speculate on its long-time properties?\n",
        "\n",
        "<div>\n",
        "   <img src=\"https://github.com/thomasmanke/ABS/raw/main/figures/MC_AbsorbingGraph.jpg\",  align=left width=\"800\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvv08HRprAJn"
      },
      "source": [
        "**Task (5 min):** \n",
        "\n",
        "Let's test it numerically! Define the corresponding transition matrix $P$ and run the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn5AuyJr4l_h"
      },
      "outputs": [],
      "source": [
        "%%script echo Edit before executing\n",
        "P= ....\n",
        "\n",
        "X = generate_sequence(P)\n",
        "print(*X, sep='')\n",
        "\n",
        "states, counts = np.unique(X, return_counts=True)\n",
        "B = plt.bar(states.astype(str), counts, align='center', width=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cxOfxIDOFCC"
      },
      "source": [
        "**Task (5 min)**: What was the initial state? Modify the above code to chose a different initial state. How does the output change?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S0wQGfzSjoL"
      },
      "source": [
        "**Lesson:** Some Markov Chains (transition matrices) can have **absorbing states**. More generally there could be multiple absorbing states."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usoB9DLcTVBm"
      },
      "source": [
        "## Visualizating Matrix Powers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiPRxprJO4jh"
      },
      "source": [
        "Let's make the temporal analysis more visually pleasing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe4GI9sHN3Nl"
      },
      "outputs": [],
      "source": [
        "from numpy.linalg import matrix_power\n",
        "fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(10,5))\n",
        "i=0\n",
        "for t in [0,1,2,10,100]:\n",
        "  S=matrix_power(P,t)\n",
        "  im=ax[i].imshow(S, cmap=plt.cm.Blues)\n",
        "  ax[i].set_title(t)\n",
        "  i = i + 1\n",
        "\n",
        "cax = fig.add_axes([0.1, 0.2, 0.8, 0.05])\n",
        "fig.colorbar(im, cax=cax, orientation='horizontal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU3m_FwWVdEq"
      },
      "source": [
        "**Discussion**: What do we see here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnuf-rVhXhom"
      },
      "source": [
        "I'm proud of the above visualization, so let's make it a (slightly more flexible) function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JeojLU5WUBV"
      },
      "outputs": [],
      "source": [
        "def plot_transition_matrix(P, tmax=100):\n",
        "\n",
        "  # some sanity checks\n",
        "  assert P.shape[0]==P.shape[1],         \"P should be a squared matrix\"\n",
        "  assert np.allclose( P.sum(axis=1), 1), \"P should be a stochastic matrix\"\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(10,5))\n",
        "  i=0\n",
        "  for t in [0,1,2,10,tmax]:\n",
        "    S=matrix_power(P,t)\n",
        "    im=ax[i].imshow(S, cmap=plt.cm.Blues)\n",
        "    ax[i].set_title(t)\n",
        "    i = i + 1\n",
        "  cax = fig.add_axes([0.1, 0.2, 0.8, 0.05])\n",
        "  fig.colorbar(im, cax=cax, orientation='horizontal')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61AzM-xhTEAm"
      },
      "source": [
        "## Convergence Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH6fOUGCFZRS"
      },
      "source": [
        "We saw that the Markov chain above converges to some asymptotic state - let's explore and modify this behaviour."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MBilrXqP4Ph"
      },
      "source": [
        "**Group Tasks (30min):** \n",
        "Adjust the parameters in $P$ to\n",
        "\n",
        "1. **delay the convergence** to the absorbing state 3.\n",
        "2. generates **two absorbing states**\n",
        "3. avoid absorbing states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ThbITqeP4Pi",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%script echo Edit before eexeecution\n",
        "P1=np.array(...)\n",
        "P2=np.array(...)\n",
        "P3=np.array(...)\n",
        "\n",
        "plot_transition_matrix(P1, 100)\n",
        "plot_transition_matrix(P2, 100)\n",
        "plot_transition_matrix(P3, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuTuFKdsbSM0"
      },
      "source": [
        "**Lessons:** The long time behaviour depends on model structure and parameters\n",
        "\n",
        "1. Parameters may control convergence rate\n",
        "2. structural aspects (state accessibilty)may cause multiple absorbing states. The Markov chain will still converge. But $\\to$ initial state sensitivity\n",
        "3. some (interesting) Markov chains have a unique stationary state that is independent from the initial state.\n",
        "\n",
        "**Notice:** \n",
        "\n",
        "- stationary distribution (sometimes called steady state distribution) **does not** mean that the states don't change, but that the probability distribution is constant over time (and independent of the initial state)\n",
        "- the power method is a simple but expensive way to determine the stationary distribution $\\pi$, but there are more effcient ways using the eigenvalue formulation\n",
        "$$\\pi = \\pi \\cdot P$$\n",
        "- this formula also exends the idea of the stationary distribution beyond the long-term behaviour of a Markov chain; a stationary distribution is a distribution that stays fixed after application of $P$ (regardless of whether it can be reached through an asymptotic process)\n",
        "- a Markov chain can have several stationary distributions\n",
        "- Many Markov chains have a unique stationary distribution and they are usually the most interesting/important ones. However, we need to be aware of - and protect against - other possibilities (see below)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIS3MlbCn3vw"
      },
      "source": [
        "## Periodic States"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWxOoTvsQL1r"
      },
      "source": [
        "Often we want to avoid periodicity as another \"pathological\" condition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsxuvstVn6TH"
      },
      "outputs": [],
      "source": [
        "P=np.array([[0.0,1.0,0.0],\n",
        "            [0.5,0.0,0.5],\n",
        "            [0.0,1.0,0.0]])\n",
        "\n",
        "plot_transition_matrix(P, 11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EScwBo45qk-s"
      },
      "source": [
        "\n",
        "\n",
        "**Notice:** any self-transition ($P_{ii} \\ne 0$) will result in an aperiodic Markov chain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLDDDNttHZrZ"
      },
      "source": [
        "## Summary \n",
        "\n",
        "We have seen different possible behaviours of Markov chains\n",
        "1. convergence to unique state (stationary or absorbing)\n",
        "2. convergence to non-unique state: inital state sensitivity\n",
        "3. periodic behaviour\n",
        "\n",
        "\"Nice\" Markov chains are \"ergodic\" (everything that can happen will eventually happen) and \"non-periodic\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idrA5RrcZ3mU"
      },
      "source": [
        "## Expected Times: Convergence and Return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJNT1vo7aE8f"
      },
      "source": [
        "### Convergence Time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoD6u3V74PiF"
      },
      "source": [
        "The convergence of a Markov chain $P$ to its stationary distribution $\\pi$ is a very important property. \n",
        "\n",
        "Starting from state $\\pi_0=(1, 0)$ the approximation to the stationary distribution\n",
        "is given by\n",
        "\n",
        "$$\n",
        "\\pi_t = \\pi_0 P^t\n",
        "$$\n",
        "\n",
        "The distance from the stationary distribution is given by the Euclidean norm\n",
        "$$\n",
        "\\delta(t) = ||\\pi_t - \\pi||\n",
        "$$\n",
        "\n",
        "see also numpy: np.linalg.norm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAqmWd3l55Be"
      },
      "source": [
        "**Task (10 min)**: \n",
        "\n",
        "Asymptotically the Markov chain defined by $P$ (above) has stationary distribution $\\pi=(1/3, 2/3)$. Calculate the distance of $\\delta(t)$ and plot it logarithmically against $t=1 \\ldots 50$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6l2Finu0X3t"
      },
      "outputs": [],
      "source": [
        "%%script echo Edit before executing\n",
        "from numpy.linalg import matrix_power\n",
        "\n",
        "P  = np.array([[0.8, 0.2],[0.1,0.9]])  # transition matrix\n",
        "pi = np.array([1./3, 2./3])            # stationatry distribution\n",
        "T  = 50                                # maximal number of times\n",
        "\n",
        "pi_0 = np.array([1,0])                 # initial distribution\n",
        "\n",
        "dist = np.zeros(T)                     # initialize T distances\n",
        "for t in range(T):\n",
        "  pi_t =        # hint: P^t\n",
        "  dist[t] = ... # calculate distance --> hint: np.linalg.norm\n",
        "#  print(pi_t, dist[t])\n",
        "\n",
        "plt.plot(dist)\n",
        "plt.yscale('log')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('distance from stationary')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ0lYpbq5iVT"
      },
      "source": [
        "**Message**: The convergence is exponential. The precise rate is controlled by matrix properties of $P$ (its eigenvalues)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7d-wT9JgaYV"
      },
      "source": [
        "### State Duration\n",
        "\n",
        "How long is the expected stay $E[t_i]$ in a given state $i$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aic8mxrHgwEo"
      },
      "source": [
        "$$\n",
        "Pr(X_1=i, X_2=i, \\ldots X_{t}=i, X_{t+1} \\ne i) = p_{ii}^{t-1} (1-p_{ii}) \\equiv p_i(t) \\\\ \\\\\n",
        "E[t_i] = \\sum_{t=1}^\\infty t p_i(t) = (1-p_{ii}) \\sum_t t p_{ii}^{t-1} = \\frac{1}{1-p_{ii}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_jl6iRbiQb2"
      },
      "source": [
        "**Task (10 min):** Define your favorite Markov Model (transition matrix) and generate a (sufficiently) long sequence from it. Pick a specific state $i$ and confirm the above formula. A simple helper function is provided below, but try to understand it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYV1f6zIlJ0p"
      },
      "outputs": [],
      "source": [
        "def StateDuration(L, s=0):\n",
        "  # helper function to calculate the \"duration\" of a given element s in list L\n",
        "  # --> calculate the length of consecutive occurences\n",
        "  count=0\n",
        "  res=[]\n",
        "  for e in L:\n",
        "    if e==s:\n",
        "      count +=1\n",
        "    else:\n",
        "      if (count > 0):\n",
        "        res.append(count)\n",
        "      count=0\n",
        "\n",
        "  if (count>0):\n",
        "    res.append(count)\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q1vGS29iaKi"
      },
      "outputs": [],
      "source": [
        "%%script echo Edit before executing\n",
        "P = np.array( ... your choice here)  # chose transition matrix\n",
        "i=0                                   # chose states\n",
        "\n",
        "X=generate_sequence(P, T= ... )\n",
        "\n",
        "exp = ... # expected duration\n",
        "res = StateDuration(...)\n",
        "print('expected duration: {} average: {}'.format(exp, sum(res)/len(res)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCPqgKSSgk2Y"
      },
      "source": [
        "# Parameter Estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rfKNz30To0V"
      },
      "source": [
        "Given transition rates $P_{ij}$ we can calculate (or simulate) many interesting quantities (path probabilities, stationary states, absorbing states, mixing times, ...).\n",
        "\n",
        "How can we estimate (learn) these model parameters?\n",
        "\n",
        "Frequency interpretation:\n",
        "\n",
        "$$\n",
        "P_{ij} = \\frac{N_{ij}}{\\sum_j N_{ij}}\n",
        "$$\n",
        "\n",
        "\n",
        "Remember: All models are wrong, some are useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC3u7vVSIpbK"
      },
      "source": [
        "**Group Task (15 min):** Given a sequence of states. Complete the code below to obtain the parameters of the Markov Chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyqdq3oRJDBm"
      },
      "outputs": [],
      "source": [
        "%%script echo Edit before executing\n",
        "import numpy as np\n",
        "X=[0,1,1,1,0,1,0]\n",
        "L= ...      # length of observed sequence\n",
        "N=2         # number of states \n",
        "\n",
        "P = np.zeros((N,N))\n",
        "for i in range( .... ):\n",
        "\n",
        "  [ ... fill P_ij_ ...]\n",
        "\n",
        "# normalize rows\n",
        "P = P/np.sum(P,axis=1, keepdims=True)\n",
        "print('estimated transition matrix: \\n', P)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_MPVEXSR5Wz"
      },
      "source": [
        "**Question:** How would you estimate the intial probabiltiy?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "GLDDDNttHZrZ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}